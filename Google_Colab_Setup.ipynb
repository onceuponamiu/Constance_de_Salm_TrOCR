{"cells":[{"cell_type":"markdown","metadata":{"id":"bPCYC0_BBW8f"},"source":["# TrOCR Training on Google Colab 🚀\n","\n","Notebook này hướng dẫn setup và training TrOCR trên Google Colab với GPU miễn phí.\n","\n","## 📋 Chuẩn bị\n","1. Upload folder `trocr-htr` lên Google Drive\n","2. Upload dữ liệu training (ảnh + XML files)\n","3. Kết nối Google Drive với Colab\n","4. Cài đặt dependencies\n","5. Training với GPU\n","\n","## ⚡ GPU Info\n","- Google Colab cung cấp Tesla T4 (16GB VRAM)\n","- Thời gian training estimate: 2-4 giờ\n","- Khuyến nghị sử dụng Colab Pro cho ổn định\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"twlUdik8BW8h","executionInfo":{"status":"ok","timestamp":1755403325665,"user_tz":-420,"elapsed":9176,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"30dc9662-765a-44c2-e923-742230934e09"},"outputs":[{"output_type":"stream","name":"stdout","text":["🔥 GPU Information:\n","CUDA available: True\n","GPU count: 1\n","GPU name: Tesla T4\n","GPU memory: 15.8 GB\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Bước 1: Kiểm tra GPU và mount Google Drive\n","import torch\n","import os\n","\n","# Kiểm tra GPU\n","print(\"🔥 GPU Information:\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU count: {torch.cuda.device_count()}\")\n","    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n","else:\n","    print(\"⚠️ GPU not available! Go to Runtime -> Change runtime type -> Hardware accelerator -> GPU\")\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"P4L-tKZqBW8h","executionInfo":{"status":"ok","timestamp":1755403325674,"user_tz":-420,"elapsed":7,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"123d4fad-a44d-43eb-81d4-73095c66071f"},"outputs":[{"output_type":"stream","name":"stdout","text":["🔧 Setting up paths...\n","Project root: /content/drive/MyDrive/Constance_de_Salm_TrOCR\n","TrOCR directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n","Data directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data\n","✅ TrOCR directory found\n","✅ Data directory found\n","📁 Current directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n"]}],"source":["# Bước 2: Setup paths và cài đặt dependencies\n","import os\n","import sys\n","\n","# Định nghĩa paths\n","PROJECT_ROOT = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR\"\n","TROCR_DIR = f\"{PROJECT_ROOT}/trocr-htr\"\n","DATA_DIR = f\"{PROJECT_ROOT}/training-data\"\n","\n","print(f\"🔧 Setting up paths...\")\n","print(f\"Project root: {PROJECT_ROOT}\")\n","print(f\"TrOCR directory: {TROCR_DIR}\")\n","print(f\"Data directory: {DATA_DIR}\")\n","\n","# Kiểm tra xem folders đã upload chưa\n","if not os.path.exists(TROCR_DIR):\n","    print(f\"❌ TrOCR directory not found: {TROCR_DIR}\")\n","    print(\"👉 Please upload the trocr-htr folder to your Google Drive first!\")\n","else:\n","    print(f\"✅ TrOCR directory found\")\n","\n","if not os.path.exists(DATA_DIR):\n","    print(f\"❌ Data directory not found: {DATA_DIR}\")\n","    print(\"👉 Please upload training data to your Google Drive first!\")\n","else:\n","    print(f\"✅ Data directory found\")\n","\n","# Change to TrOCR directory\n","os.chdir(TROCR_DIR)\n","sys.path.append(TROCR_DIR)\n","print(f\"📁 Current directory: {os.getcwd()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"j3evok4HBW8i","executionInfo":{"status":"ok","timestamp":1755403377307,"user_tz":-420,"elapsed":51632,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"7d14feba-6f97-40f4-d145-fb8d94e89882"},"outputs":[{"output_type":"stream","name":"stdout","text":["📦 Installing dependencies...\n","Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n","Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.55.1)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.21.0+cu124)\n","Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.6.0+cu124)\n","Requirement already satisfied: opencv-python>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n","Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n","Requirement already satisfied: albumentations>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.0.8)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.2.2)\n","Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.0.2)\n","Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.6.1)\n","Requirement already satisfied: jiwer>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.0.0)\n","Requirement already satisfied: rapidfuzz>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (3.13.0)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (3.10.0)\n","Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (0.13.2)\n","Requirement already satisfied: plotly>=5.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (5.24.1)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (4.67.1)\n","Requirement already satisfied: wandb>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.21.1)\n","Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (6.0.2)\n","Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.3.0)\n","Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (1.1.1)\n","Requirement already satisfied: ipywidgets>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (8.1.7)\n","Requirement already satisfied: jupyterlab>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (4.4.6)\n","Requirement already satisfied: lxml>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (5.4.0)\n","Requirement already satisfied: beautifulsoup4>=4.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (4.13.4)\n","Requirement already satisfied: editdistance>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (0.8.1)\n","Requirement already satisfied: Levenshtein>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (0.27.1)\n","Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (4.0.0)\n","Requirement already satisfied: accelerate>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (1.10.0)\n","Requirement already satisfied: deepspeed>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 52)) (0.17.4)\n","Requirement already satisfied: lightning>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 53)) (2.5.3)\n","Requirement already satisfied: black>=23.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 56)) (25.1.0)\n","Requirement already satisfied: flake8>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 57)) (7.3.0)\n","Requirement already satisfied: pytest>=7.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 58)) (8.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (0.34.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (25.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (0.6.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35.0->-r requirements.txt (line 2)) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35.0->-r requirements.txt (line 2)) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35.0->-r requirements.txt (line 2)) (1.1.7)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (1.16.1)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (2.11.7)\n","Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (0.0.24)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (4.12.0.88)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 10)) (3.12.6)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 10)) (6.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 15)) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 15)) (3.6.0)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer>=3.0.0->-r requirements.txt (line 18)) (8.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (3.2.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.15.0->-r requirements.txt (line 24)) (9.1.2)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (3.1.45)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (5.29.5)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (2.34.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 10)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 10)) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 10)) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (2025.8.3)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.3.0->-r requirements.txt (line 32)) (4.9.3)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (6.5.7)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (6.1.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (7.16.6)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (6.17.1)\n","Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.2.3)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (4.0.14)\n","Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (3.0.15)\n","Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.0.5)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.28.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (5.8.1)\n","Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.2.6)\n","Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.16.0)\n","Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.27.3)\n","Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.2.4)\n","Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (75.2.0)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (6.4.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.16.0)\n","Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (25.1.0)\n","Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (7.4.9)\n","Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.12.0)\n","Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.5.3)\n","Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (5.10.4)\n","Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (7.7.0)\n","Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.22.1)\n","Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (26.2.1)\n","Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.18.1)\n","Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.8.0)\n","Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.17.0)\n","Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.12.1)\n","Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (4.25.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 41)) (2.7)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (0.70.16)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (3.12.15)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.24.0->-r requirements.txt (line 49)) (5.9.5)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (0.8.1)\n","Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (3.1.0)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (1.1.1)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (1.13.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (9.0.0)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (12.575.51)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 53)) (0.15.2)\n","Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 53)) (1.8.1)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 53)) (2.5.3)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black>=23.0.0->-r requirements.txt (line 56)) (1.1.0)\n","Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black>=23.0.0->-r requirements.txt (line 56)) (0.12.1)\n","Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8>=6.0.0->-r requirements.txt (line 57)) (0.7.0)\n","Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from flake8>=6.0.0->-r requirements.txt (line 57)) (2.14.0)\n","Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from flake8>=6.0.0->-r requirements.txt (line 57)) (3.4.0)\n","Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 58)) (2.1.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 58)) (1.6.0)\n","Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 58)) (2.19.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (1.20.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.3.1)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (25.1.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 28)) (4.0.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 28)) (5.0.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.8.15)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.6.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (3.0.51)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (4.9.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.2.13)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.8.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 3)) (3.0.2)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.27.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.4)\n","Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (3.3.0)\n","Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.1.4)\n","Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.1.1)\n","Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.5.1)\n","Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (20.11.0)\n","Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (3.0.0)\n","Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.1.0)\n","Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.3.0)\n","Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (24.11.1)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.5.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.21.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.7.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 13)) (1.17.0)\n","Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.2.2)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.22)\n","Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.3.0)\n","Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.9.0.20250809)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.2.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.3.1)\n","✅ Dependencies installed successfully!\n","🔥 Key libraries checked:\n","  - Transformers: 4.55.1\n","  - PyTorch: 2.6.0+cu124\n","  - CUDA available: True\n","✅ Custom modules imported successfully!\n"]}],"source":["# Bước 3: Cài đặt dependencies\n","print(\"📦 Installing dependencies...\")\n","\n","# Cập nhật pip và cài đặt requirements\n","!pip install --upgrade pip\n","!pip install -r requirements.txt\n","\n","# Cài đặt thêm một số packages có thể thiếu\n","!pip install datasets>=2.14.0\n","!pip install accelerate>=0.24.0\n","!pip install jiwer>=3.0.0\n","\n","print(\"✅ Dependencies installed successfully!\")\n","\n","# Kiểm tra installations quan trọng\n","try:\n","    import transformers\n","    import torch\n","    from PIL import Image\n","    import pandas as pd\n","    import numpy as np\n","    print(f\"🔥 Key libraries checked:\")\n","    print(f\"  - Transformers: {transformers.__version__}\")\n","    print(f\"  - PyTorch: {torch.__version__}\")\n","    print(f\"  - CUDA available: {torch.cuda.is_available()}\")\n","except ImportError as e:\n","    print(f\"❌ Import error: {e}\")\n","\n","# Test import custom modules\n","try:\n","    from src.data_loader import CdSDataLoader\n","    from src.model import TrOCRForCdS\n","    from src.trainer import TrOCRTrainer\n","    print(\"✅ Custom modules imported successfully!\")\n","except ImportError as e:\n","    print(f\"❌ Custom module import error: {e}\")\n","    print(\"👉 Make sure you uploaded the src/ folder correctly\")\n"]},{"cell_type":"code","source":["# Fix paths trong config cho Colab\n","print(\"🔧 Fixing data paths for Colab...\")\n","\n","# Đọc và sửa config\n","import yaml\n","\n","# Load config hiện tại\n","with open('config/colab_config.yaml', 'r') as f:\n","    config = yaml.safe_load(f)\n","\n","# Cập nhật paths cho Colab\n","PROJECT_ROOT = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR\"\n","DATA_DIR = f\"{PROJECT_ROOT}/training-data\"\n","\n","# Sửa source_dirs\n","config['data']['source_dirs'] = [\n","    f\"{DATA_DIR}/verite-terrain/\",\n","    f\"{DATA_DIR}/sample-images/\",\n","    f\"{DATA_DIR}/predic-corrigees/\"\n","]\n","\n","# Sửa output paths\n","config['data']['output_dir'] = f\"{PROJECT_ROOT}/outputs/data/\"\n","config['paths']['models_dir'] = f\"{PROJECT_ROOT}/outputs/models/\"\n","config['paths']['outputs_dir'] = f\"{PROJECT_ROOT}/outputs/\"\n","config['paths']['logs_dir'] = f\"{PROJECT_ROOT}/outputs/logs/\"\n","\n","# Lưu lại config đã fix\n","with open('config/colab_config_fixed.yaml', 'w') as f:\n","    yaml.dump(config, f, default_flow_style=False)\n","\n","print(\"✅ Config paths fixed!\")\n","\n","# Kiểm tra paths có tồn tại không\n","print(\"\\n📁 Checking data directories:\")\n","for source_dir in config['data']['source_dirs']:\n","    if os.path.exists(source_dir):\n","        files = os.listdir(source_dir)\n","        print(f\"  ✅ {source_dir}: {len(files)} files\")\n","        # Show examples\n","        img_files = [f for f in files if f.lower().endswith(('.jpg', '.tif', '.png'))]\n","        xml_files = [f for f in files if f.lower().endswith('.xml')]\n","        print(f\"     Images: {len(img_files)}, XML: {len(xml_files)}\")\n","        if img_files:\n","            print(f\"     Example: {img_files[0]}\")\n","    else:\n","        print(f\"  ❌ {source_dir}: NOT FOUND\")\n","        print(f\"     👉 Need to upload data to this path\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOXnOxXCFDIf","executionInfo":{"status":"ok","timestamp":1755403377325,"user_tz":-420,"elapsed":17,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"4210e22c-21f5-4f85-d0c2-1c9412fabfbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🔧 Fixing data paths for Colab...\n","✅ Config paths fixed!\n","\n","📁 Checking data directories:\n","  ✅ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/verite-terrain/: 78 files\n","     Images: 33, XML: 45\n","     Example: CdS02_Konv002-01_0034.jpg\n","  ✅ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/sample-images/: 107 files\n","     Images: 107, XML: 0\n","     Example: CdS02_Konv002-02_0001.tif\n","  ✅ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/predic-corrigees/: 20 files\n","     Images: 0, XML: 20\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"zRLFkEcjBW8i","executionInfo":{"status":"ok","timestamp":1755403380271,"user_tz":-420,"elapsed":2945,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"77994090-de3f-4735-d14d-29a8c83ee6d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["📊 Data exploration with fixed config...\n","✅ Fixed configuration loaded\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","/content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr/src/data_loader.py:111: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  transforms.append(A.GaussNoise(var_limit=(0, aug_config['noise_factor']), p=0.2))\n"]},{"output_type":"stream","name":"stdout","text":["🔍 Scanning for training data...\n","📊 Data Summary:\n","  - Total image-text pairs: 33\n","  - Average text length: 2360.2 characters\n","✅ Data found successfully!\n","📝 Sample text: Chacun connait cet apologue : \"Un peintre avait exposé un tableau représentant un lion terrassé \"par...\n","🖼️ Sample image: /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/verite-terrain/CdS02_Konv002-01_0034.jpg\n","  - Min text length: 1180\n","  - Max text length: 3927\n","  - Texts under 10 chars: 0\n","\n","📁 Final data directories check:\n","  ✅ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/verite-terrain/\n","     📷 Images: 33\n","     📄 XML files: 45\n","     🔗 Matching pairs found: 33\n","  ✅ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/sample-images/\n","     📷 Images: 107\n","     📄 XML files: 0\n","     🔗 Matching pairs found: 0\n","  ✅ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/predic-corrigees/\n","     📷 Images: 0\n","     📄 XML files: 20\n","     🔗 Matching pairs found: 0\n"]}],"source":["print(\"📊 Data exploration with fixed config...\")\n","\n","from src.data_loader import CdSDataLoader\n","from src.utils import load_config\n","\n","# Load config đã fix\n","config = load_config('config/colab_config_fixed.yaml', 'config/base_config.yaml')\n","print(\"✅ Fixed configuration loaded\")\n","\n","# Initialize data loader\n","data_loader = CdSDataLoader(config)\n","\n","# Find data\n","print(\"🔍 Scanning for training data...\")\n","image_paths, texts = data_loader.find_image_text_pairs(config['data']['source_dirs'])\n","\n","print(f\"📊 Data Summary:\")\n","print(f\"  - Total image-text pairs: {len(image_paths)}\")\n","\n","if len(texts) > 0:\n","    avg_length = sum(len(text) for text in texts) / len(texts)\n","    print(f\"  - Average text length: {avg_length:.1f} characters\")\n","    print(f\"✅ Data found successfully!\")\n","    print(f\"📝 Sample text: {texts[0][:100]}...\")\n","    print(f\"🖼️ Sample image: {image_paths[0]}\")\n","\n","    # Show text length distribution\n","    lengths = [len(text) for text in texts]\n","    print(f\"  - Min text length: {min(lengths)}\")\n","    print(f\"  - Max text length: {max(lengths)}\")\n","    print(f\"  - Texts under 10 chars: {sum(1 for l in lengths if l < 10)}\")\n","\n","else:\n","    print(f\"❌ No training data found!\")\n","    print(f\"👉 Kiểm tra lại data paths:\")\n","    for source_dir in config['data']['source_dirs']:\n","        print(f\"   {source_dir}\")\n","\n","print(f\"\\n📁 Final data directories check:\")\n","for source_dir in config['data']['source_dirs']:\n","    if os.path.exists(source_dir):\n","        files = os.listdir(source_dir)\n","        img_files = [f for f in files if f.lower().endswith(('.jpg', '.tif', '.png', '.jpeg'))]\n","        xml_files = [f for f in files if f.lower().endswith('.xml')]\n","        print(f\"  ✅ {source_dir}\")\n","        print(f\"     📷 Images: {len(img_files)}\")\n","        print(f\"     📄 XML files: {len(xml_files)}\")\n","        print(f\"     🔗 Matching pairs found: {len([img for img in img_files if any(xml.startswith(img.split('.')[0]) for xml in xml_files)])}\")\n","    else:\n","        print(f\"  ❌ {source_dir}: NOT FOUND\")"]},{"cell_type":"code","source":["print(\"🎯 Preparing for training with 33 samples...\")\n","\n","# Update config để phù hợp với dataset nhỏ\n","import yaml\n","\n","# Load config\n","with open('config/colab_config_fixed.yaml', 'r') as f:\n","    config = yaml.safe_load(f)\n","\n","# Điều chỉnh cho dataset nhỏ (33 samples)\n","config['training'].update({\n","    'batch_size': 1,                    # Batch size nhỏ\n","    'gradient_accumulation_steps': 4,   # Effective batch = 4\n","    'num_epochs': 20,                   # Tăng epochs cho dataset nhỏ\n","    'learning_rate': 5e-5,              # Learning rate cao hơn\n","    'save_steps': 10,                   # Save thường xuyên\n","    'eval_steps': 20,                   # Eval thường xuyên\n","    'logging_steps': 5,                 # Log chi tiết\n","    'warmup_steps': 10,                 # Ít warmup steps\n","    'early_stopping_patience': 5       # Patience cao hơn\n","})\n","\n","# Điều chỉnh data split cho dataset nhỏ\n","config['data'].update({\n","    'train_split': 0.8,    # 26 samples train\n","    'val_split': 0.1,      # 3 samples val\n","    'test_split': 0.1      # 4 samples test\n","})\n","\n","# Lưu config optimized\n","with open('config/colab_small_dataset.yaml', 'w') as f:\n","    yaml.dump(config, f, default_flow_style=False)\n","\n","print(\"✅ Config optimized for small dataset (33 samples)\")\n","\n","# Estimate training time\n","num_samples = 33\n","train_samples = int(num_samples * 0.8)  # 26 samples\n","batch_size = config['training']['batch_size']\n","gradient_accumulation_steps = config['training']['gradient_accumulation_steps']\n","num_epochs = config['training']['num_epochs']\n","\n","effective_batch_size = batch_size * gradient_accumulation_steps\n","steps_per_epoch = max(1, train_samples // effective_batch_size)\n","total_steps = steps_per_epoch * num_epochs\n","estimated_time_minutes = total_steps * 30 / 60  # ~30 seconds per step for small dataset\n","\n","print(f\"⏱️ Training estimates:\")\n","print(f\"  - Total samples: {num_samples}\")\n","print(f\"  - Train/Val/Test: {train_samples}/3/4\")\n","print(f\"  - Effective batch size: {effective_batch_size}\")\n","print(f\"  - Steps per epoch: {steps_per_epoch}\")\n","print(f\"  - Total epochs: {num_epochs}\")\n","print(f\"  - Total steps: {total_steps}\")\n","print(f\"  - Estimated time: {estimated_time_minutes:.0f} minutes\")\n","\n","print(f\"\\n🚀 Ready to start training!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJo5AkDVFuzR","executionInfo":{"status":"ok","timestamp":1755403380349,"user_tz":-420,"elapsed":22,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"78e35f97-de59-4450-bb28-65391929b503"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🎯 Preparing for training with 33 samples...\n","✅ Config optimized for small dataset (33 samples)\n","⏱️ Training estimates:\n","  - Total samples: 33\n","  - Train/Val/Test: 26/3/4\n","  - Effective batch size: 4\n","  - Steps per epoch: 6\n","  - Total epochs: 20\n","  - Total steps: 120\n","  - Estimated time: 60 minutes\n","\n","🚀 Ready to start training!\n"]}]},{"cell_type":"code","source":["# Fix import paths cho scripts\n","print(\"🔧 Fixing import paths...\")\n","\n","import sys\n","import os\n","\n","# Đảm bảo current directory đúng\n","current_dir = os.getcwd()\n","print(f\"Current directory: {current_dir}\")\n","\n","# Add paths to Python path\n","trocr_dir = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\"\n","if trocr_dir not in sys.path:\n","    sys.path.insert(0, trocr_dir)\n","\n","# Change to trocr directory\n","os.chdir(trocr_dir)\n","print(f\"Changed to: {os.getcwd()}\")\n","\n","# Test imports\n","try:\n","    from src.trainer import TrOCRTrainer\n","    from src.data_loader import CdSDataLoader\n","    from src.model import TrOCRForCdS\n","    print(\"✅ All imports successful!\")\n","except ImportError as e:\n","    print(f\"❌ Import error: {e}\")\n","    print(\"📁 Checking src directory:\")\n","    if os.path.exists('src'):\n","        print(\"  ✅ src/ directory exists\")\n","        src_files = os.listdir('src')\n","        print(f\"  📄 Files in src/: {src_files}\")\n","    else:\n","        print(\"  ❌ src/ directory not found!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ma5zpqYUGmr5","executionInfo":{"status":"ok","timestamp":1755403380398,"user_tz":-420,"elapsed":48,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"71dad807-ba81-4eb6-d9d0-c56dbd1f3554"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🔧 Fixing import paths...\n","Current directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n","Changed to: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n","✅ All imports successful!\n"]}]},{"cell_type":"code","source":["# Fix TrainingArguments compatibility\n","print(\"🔧 Fixing TrainingArguments compatibility...\")\n","\n","import transformers\n","print(f\"Transformers version: {transformers.__version__}\")\n","\n","# Check which parameter name is correct\n","from transformers import TrainingArguments\n","import inspect\n","\n","# Get the signature of TrainingArguments.__init__\n","sig = inspect.signature(TrainingArguments.__init__)\n","params = list(sig.parameters.keys())\n","\n","print(\"Available TrainingArguments parameters:\")\n","eval_params = [p for p in params if 'eval' in p.lower()]\n","print(f\"Evaluation-related params: {eval_params}\")\n","\n","# Check if it's 'evaluation_strategy' or 'eval_strategy'\n","if 'evaluation_strategy' in params:\n","    print(\"✅ Uses 'evaluation_strategy'\")\n","    eval_strategy_param = 'evaluation_strategy'\n","elif 'eval_strategy' in params:\n","    print(\"✅ Uses 'eval_strategy'\")\n","    eval_strategy_param = 'eval_strategy'\n","else:\n","    print(\"❌ No evaluation strategy parameter found\")\n","    eval_strategy_param = None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9cPjFnSHI8y","executionInfo":{"status":"ok","timestamp":1755403380402,"user_tz":-420,"elapsed":3,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"7e6dce06-d2aa-40b6-c060-8a0c6f15a3af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🔧 Fixing TrainingArguments compatibility...\n","Transformers version: 4.55.1\n","Available TrainingArguments parameters:\n","Evaluation-related params: ['do_eval', 'eval_strategy', 'per_device_eval_batch_size', 'per_gpu_eval_batch_size', 'eval_accumulation_steps', 'eval_delay', 'jit_mode_eval', 'bf16_full_eval', 'fp16_full_eval', 'eval_steps', 'eval_do_concat_batches', 'batch_eval_metrics', 'eval_on_start', 'eval_use_gather_object']\n","✅ Uses 'eval_strategy'\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iQDypA1WBW8i","executionInfo":{"status":"ok","timestamp":1755405505828,"user_tz":-420,"elapsed":1165015,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"6464e542-08ab-422b-9026-93ffa9559ed3"},"outputs":[{"output_type":"stream","name":"stdout","text":["🔧 Fixing model configuration...\n","📊 Initializing with fixed model config...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["✅ Model config fixed:\n","  decoder_start_token_id: 0\n","  pad_token_id: 1\n","  vocab_size: 50265\n","  max_length: 384\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr/src/data_loader.py:111: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  transforms.append(A.GaussNoise(var_limit=(0, aug_config['noise_factor']), p=0.2))\n"]},{"output_type":"stream","name":"stdout","text":["✅ Data: Train=25, Val=4, Test=4\n","✅ Trainer created with fixed model config\n","🔥 Starting training (take 3 - with fixed config)...\n"]},{"output_type":"stream","name":"stderr","text":["`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [140/140 18:33, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>7.837000</td>\n","      <td>7.388140</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>6.775600</td>\n","      <td>6.829752</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>6.481700</td>\n","      <td>6.672448</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>6.335700</td>\n","      <td>6.589857</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>6.236100</td>\n","      <td>6.561946</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>6.161400</td>\n","      <td>6.563494</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>6.051200</td>\n","      <td>6.558358</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>5.950500</td>\n","      <td>6.560427</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>5.976800</td>\n","      <td>6.558934</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>5.890100</td>\n","      <td>6.568191</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>5.860600</td>\n","      <td>6.560747</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>5.881800</td>\n","      <td>6.559472</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>5.765000</td>\n","      <td>6.560268</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>5.699200</td>\n","      <td>6.558624</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3917: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 384, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","There were missing keys in the checkpoint model loaded: ['decoder.output_projection.weight'].\n"]},{"output_type":"stream","name":"stdout","text":["🎉 Training completed!\n","📊 Training Results:\n","  Final loss: 6.3331\n","  Steps completed: 140\n","💾 Model saved to: /content/drive/MyDrive/Constance_de_Salm_TrOCR/outputs/models/final\n","🧪 Testing model với một sample...\n","📝 Sample prediction:\n","  Reference: 1818 (de Mme la Princesse de Salm) Lettre A Mr Raboteau Dyck, ce 6 Décembre, 1818. Un mot seulement,...\n","  Prediction: 18 ( M. A. M. de..,... de,.,,. de de., de. deé..'..é.,',,, de,,'.,é,.', de de, de',.é,,é. de' de.' d...\n","🎉 Training and testing completed successfully!\n"]}],"source":["# 🔧 Fix model configuration với decoder_start_token_id\n","print(\"🔧 Fixing model configuration...\")\n","\n","from src.data_loader import CdSDataLoader\n","from src.model import TrOCRForCdS\n","from transformers import TrainingArguments, Trainer, VisionEncoderDecoderModel, TrOCRProcessor\n","from src.utils import load_config\n","import torch\n","\n","# Load config\n","config = load_config('config/colab_small_dataset.yaml', 'config/base_config.yaml')\n","PROJECT_ROOT = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR\"\n","config['paths']['models_dir'] = f\"{PROJECT_ROOT}/outputs/models/\"\n","\n","import os\n","os.makedirs(config['paths']['models_dir'], exist_ok=True)\n","\n","print(\"📊 Initializing with fixed model config...\")\n","\n","# 1. Load model and processor manually với config fix\n","model_name = config['model']['name']\n","processor = TrOCRProcessor.from_pretrained(model_name)\n","model = VisionEncoderDecoderModel.from_pretrained(model_name)\n","\n","# FIX: Set decoder_start_token_id\n","model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n","model.config.pad_token_id = processor.tokenizer.pad_token_id\n","\n","# Additional config fixes for training\n","model.config.vocab_size = model.config.decoder.vocab_size\n","model.config.max_length = config['model']['max_length']\n","model.config.no_repeat_ngram_size = 3\n","model.config.early_stopping = True\n","model.config.length_penalty = 2.0\n","model.config.num_beams = 4\n","\n","print(f\"✅ Model config fixed:\")\n","print(f\"  decoder_start_token_id: {model.config.decoder_start_token_id}\")\n","print(f\"  pad_token_id: {model.config.pad_token_id}\")\n","print(f\"  vocab_size: {model.config.vocab_size}\")\n","print(f\"  max_length: {model.config.max_length}\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# 2. Data\n","data_loader = CdSDataLoader(config)\n","train_dataset, val_dataset, test_dataset = data_loader.create_datasets()\n","print(f\"✅ Data: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n","\n","# 3. Fixed collate function\n","def collate_fn_fixed(batch):\n","    \"\"\"Fixed collate function for training\"\"\"\n","    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n","    labels = torch.stack([item['labels'] for item in batch])\n","\n","    return {\n","        'pixel_values': pixel_values,\n","        'labels': labels\n","    }\n","\n","# 4. TrainingArguments với wandb disabled\n","training_args = TrainingArguments(\n","    output_dir=config['paths']['models_dir'],\n","    num_train_epochs=config['training']['num_epochs'],\n","    per_device_train_batch_size=config['training']['batch_size'],\n","    per_device_eval_batch_size=config['training']['batch_size'],\n","    gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n","    learning_rate=config['training']['learning_rate'],\n","    weight_decay=config['training']['weight_decay'],\n","    warmup_steps=config['training']['warmup_steps'],\n","    eval_strategy=\"steps\",\n","    eval_steps=10,\n","    save_strategy=\"steps\",\n","    save_steps=10,\n","    save_total_limit=3,\n","    logging_steps=5,\n","    logging_first_step=True,\n","    fp16=config['hardware']['mixed_precision'] == 'fp16',\n","    dataloader_num_workers=config['hardware']['dataloader_num_workers'],\n","    dataloader_pin_memory=config['hardware']['pin_memory'],\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    remove_unused_columns=False,\n","    push_to_hub=False,\n","    report_to=[],  # Empty list to disable all reporting including wandb\n","    run_name=\"trocr_colab_training\"\n",")\n","\n","# Disable wandb completely\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# 5. Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    processing_class=processor,  # Use processing_class instead of tokenizer\n","    data_collator=collate_fn_fixed\n",")\n","\n","print(\"✅ Trainer created with fixed model config\")\n","\n","# 6. Start training\n","try:\n","    print(\"🔥 Starting training (take 3 - with fixed config)...\")\n","\n","    train_result = trainer.train()\n","    print(\"🎉 Training completed!\")\n","\n","    print(f\"📊 Training Results:\")\n","    print(f\"  Final loss: {train_result.training_loss:.4f}\")\n","    print(f\"  Steps completed: {train_result.global_step}\")\n","\n","    # Save model manually\n","    final_model_path = f\"{PROJECT_ROOT}/outputs/models/final\"\n","    os.makedirs(final_model_path, exist_ok=True)\n","\n","    model.save_pretrained(final_model_path)\n","    processor.save_pretrained(final_model_path)\n","\n","    print(f\"💾 Model saved to: {final_model_path}\")\n","\n","    # Test một sample prediction\n","    print(\"🧪 Testing model với một sample...\")\n","    model.eval()\n","    with torch.no_grad():\n","        test_sample = test_dataset[0]\n","        pixel_values = test_sample['pixel_values'].unsqueeze(0).to(device)\n","        generated_ids = model.generate(pixel_values, max_length=384)\n","        prediction = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","        reference = test_sample['text']\n","\n","        print(f\"📝 Sample prediction:\")\n","        print(f\"  Reference: {reference[:100]}...\")\n","        print(f\"  Prediction: {prediction[:100]}...\")\n","\n","    print(\"🎉 Training and testing completed successfully!\")\n","\n","except Exception as e:\n","    print(f\"❌ Training failed: {e}\")\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ruVH2vQkBW8i","executionInfo":{"status":"ok","timestamp":1755405680846,"user_tz":-420,"elapsed":59914,"user":{"displayName":"Lý Lê","userId":"14887723373539951567"}},"outputId":"981e379f-6796-4a0b-fb57-1a080b1c1926"},"outputs":[{"output_type":"stream","name":"stdout","text":["📊 Comprehensive Model Evaluation\n","==================================================\n","✅ Trained model loaded for evaluation\n","🔍 Evaluating on 4 test samples...\n","Sample 1:\n","  Reference: 1818 (de Mme la Princesse de Salm) Lettre A Mr Raboteau Dyck, ce 6 Décembre, 181...\n","  Prediction: 18 ( M. A. M la.,.. de. la,, de,é.'.é,', le. à. et. le, à, et, d. v. d, v, je. j...\n","  Length - Ref: 3580, Pred: 383\n","\n","Sample 2:\n","  Reference: Lettres ces gens là ne seront jamais heureux, ils ne méritent pas de l'être, ils...\n","  Prediction: Lre Mart Madame Madame,,..','., de. de'' de,é.é'é de deéé, et. et, v, à, le, d, ...\n","  Length - Ref: 2619, Pred: 337\n","\n","Sample 3:\n","  Reference: Lettre de Martini Madame. Je viens de recevoir votre petite lettre mais trop tar...\n","  Prediction: Lre Mart Madame Mart..,.'. de',' de,, de.é'é deé,é. et, et. v. le.re.i. d. à. l....\n","  Length - Ref: 1315, Pred: 436\n","\n","Sample 4:\n","  Reference: Lettre de Martini Madame Je vous ai vu passer au haut de ma rue avant hier à 2 h...\n","  Prediction: Lre Martiniett Madame Madame..'.,' de. de'',, de,.é'é,é de deéé. et, et. v.i. le...\n","  Length - Ref: 1697, Pred: 412\n","\n","📈 FINAL EVALUATION RESULTS:\n","========================================\n","  CER: 0.8578\n","  WER: 0.9498\n","  EXACT_MATCH: 0.0000\n","  AVG_EDIT_DISTANCE: 2018.0000\n","  SIMILARITY_RATIO: 0.2359\n","\n","🎯 PERFORMANCE ANALYSIS:\n","  Training samples: 25\n","  Training epochs: 20\n","  Training time: ~19 minutes\n","  Final training loss: 5.699\n","  Validation loss: 6.559\n","  🎉 CER < 90% - Model học được pattern cơ bản!\n","  ✅ Similarity > 20% - Model có tiềm năng\n"]}],"source":["# 📊 ĐÁNH GIÁ CHI TIẾT MODEL TRAINING\n","print(\"📊 Comprehensive Model Evaluation\")\n","print(\"=\" * 50)\n","\n","from src.evaluator import HTREvaluator\n","import torch\n","from torch.utils.data import DataLoader\n","\n","# Load trained model\n","final_model_path = f\"{PROJECT_ROOT}/outputs/models/final\"\n","trained_model = VisionEncoderDecoderModel.from_pretrained(final_model_path)\n","trained_processor = TrOCRProcessor.from_pretrained(final_model_path)\n","trained_model.to(device)\n","trained_model.eval()\n","\n","print(\"✅ Trained model loaded for evaluation\")\n","\n","# Evaluate on test set\n","predictions = []\n","references = []\n","\n","print(f\"🔍 Evaluating on {len(test_dataset)} test samples...\")\n","\n","with torch.no_grad():\n","    for i, test_sample in enumerate(test_dataset):\n","        # Get prediction\n","        pixel_values = test_sample['pixel_values'].unsqueeze(0).to(device)\n","\n","        # Try different generation strategies\n","        generated_ids = trained_model.generate(\n","            pixel_values,\n","            max_length=200,  # Shorter length to avoid repetition\n","            num_beams=3,     # Fewer beams\n","            early_stopping=True,\n","            no_repeat_ngram_size=2,  # Prevent repetition\n","            do_sample=False\n","        )\n","\n","        prediction = trained_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","        reference = test_sample['text']\n","\n","        predictions.append(prediction)\n","        references.append(reference)\n","\n","        print(f\"Sample {i+1}:\")\n","        print(f\"  Reference: {reference[:80]}...\")\n","        print(f\"  Prediction: {prediction[:80]}...\")\n","        print(f\"  Length - Ref: {len(reference)}, Pred: {len(prediction)}\")\n","        print()\n","\n","# Calculate metrics\n","evaluator = HTREvaluator({'case_sensitive': True, 'normalize_whitespace': True})\n","test_metrics = evaluator.compute_metrics(predictions, references)\n","\n","print(\"📈 FINAL EVALUATION RESULTS:\")\n","print(\"=\" * 40)\n","for metric, value in test_metrics.items():\n","    if metric in ['cer', 'wer', 'exact_match', 'similarity_ratio', 'avg_edit_distance']:\n","        print(f\"  {metric.upper()}: {value:.4f}\")\n","\n","# Compare với baseline (random)\n","print(f\"\\n🎯 PERFORMANCE ANALYSIS:\")\n","print(f\"  Training samples: 25\")\n","print(f\"  Training epochs: 20\")\n","print(f\"  Training time: ~19 minutes\")\n","print(f\"  Final training loss: 5.699\")\n","print(f\"  Validation loss: 6.559\")\n","\n","if test_metrics['cer'] < 0.9:\n","    print(f\"  🎉 CER < 90% - Model học được pattern cơ bản!\")\n","else:\n","    print(f\"  ⚠️ CER cao - Cần thêm data hoặc tuning\")\n","\n","if test_metrics['similarity_ratio'] > 0.2:\n","    print(f\"  ✅ Similarity > 20% - Model có tiềm năng\")\n","else:\n","    print(f\"  ❌ Similarity thấp - Cần cải thiện\")"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}