{"cells":[{"cell_type":"markdown","metadata":{"id":"bPCYC0_BBW8f"},"source":["# TrOCR Training on Google Colab üöÄ\n","\n","Notebook n√†y h∆∞·ªõng d·∫´n setup v√† training TrOCR tr√™n Google Colab v·ªõi GPU mi·ªÖn ph√≠.\n","\n","## üìã Chu·∫©n b·ªã\n","1. Upload folder `trocr-htr` l√™n Google Drive\n","2. Upload d·ªØ li·ªáu training (·∫£nh + XML files)\n","3. K·∫øt n·ªëi Google Drive v·ªõi Colab\n","4. C√†i ƒë·∫∑t dependencies\n","5. Training v·ªõi GPU\n","\n","## ‚ö° GPU Info\n","- Google Colab cung c·∫•p Tesla T4 (16GB VRAM)\n","- Th·ªùi gian training estimate: 2-4 gi·ªù\n","- Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng Colab Pro cho ·ªïn ƒë·ªãnh\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"twlUdik8BW8h","executionInfo":{"status":"ok","timestamp":1755403325665,"user_tz":-420,"elapsed":9176,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"30dc9662-765a-44c2-e923-742230934e09"},"outputs":[{"output_type":"stream","name":"stdout","text":["üî• GPU Information:\n","CUDA available: True\n","GPU count: 1\n","GPU name: Tesla T4\n","GPU memory: 15.8 GB\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# B∆∞·ªõc 1: Ki·ªÉm tra GPU v√† mount Google Drive\n","import torch\n","import os\n","\n","# Ki·ªÉm tra GPU\n","print(\"üî• GPU Information:\")\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"GPU count: {torch.cuda.device_count()}\")\n","    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n","else:\n","    print(\"‚ö†Ô∏è GPU not available! Go to Runtime -> Change runtime type -> Hardware accelerator -> GPU\")\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"P4L-tKZqBW8h","executionInfo":{"status":"ok","timestamp":1755403325674,"user_tz":-420,"elapsed":7,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"123d4fad-a44d-43eb-81d4-73095c66071f"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Setting up paths...\n","Project root: /content/drive/MyDrive/Constance_de_Salm_TrOCR\n","TrOCR directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n","Data directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data\n","‚úÖ TrOCR directory found\n","‚úÖ Data directory found\n","üìÅ Current directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n"]}],"source":["# B∆∞·ªõc 2: Setup paths v√† c√†i ƒë·∫∑t dependencies\n","import os\n","import sys\n","\n","# ƒê·ªãnh nghƒ©a paths\n","PROJECT_ROOT = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR\"\n","TROCR_DIR = f\"{PROJECT_ROOT}/trocr-htr\"\n","DATA_DIR = f\"{PROJECT_ROOT}/training-data\"\n","\n","print(f\"üîß Setting up paths...\")\n","print(f\"Project root: {PROJECT_ROOT}\")\n","print(f\"TrOCR directory: {TROCR_DIR}\")\n","print(f\"Data directory: {DATA_DIR}\")\n","\n","# Ki·ªÉm tra xem folders ƒë√£ upload ch∆∞a\n","if not os.path.exists(TROCR_DIR):\n","    print(f\"‚ùå TrOCR directory not found: {TROCR_DIR}\")\n","    print(\"üëâ Please upload the trocr-htr folder to your Google Drive first!\")\n","else:\n","    print(f\"‚úÖ TrOCR directory found\")\n","\n","if not os.path.exists(DATA_DIR):\n","    print(f\"‚ùå Data directory not found: {DATA_DIR}\")\n","    print(\"üëâ Please upload training data to your Google Drive first!\")\n","else:\n","    print(f\"‚úÖ Data directory found\")\n","\n","# Change to TrOCR directory\n","os.chdir(TROCR_DIR)\n","sys.path.append(TROCR_DIR)\n","print(f\"üìÅ Current directory: {os.getcwd()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"j3evok4HBW8i","executionInfo":{"status":"ok","timestamp":1755403377307,"user_tz":-420,"elapsed":51632,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"7d14feba-6f97-40f4-d145-fb8d94e89882"},"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing dependencies...\n","Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\n","Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.55.1)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.21.0+cu124)\n","Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.6.0+cu124)\n","Requirement already satisfied: opencv-python>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n","Requirement already satisfied: Pillow>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n","Requirement already satisfied: albumentations>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.0.8)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.2.2)\n","Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.0.2)\n","Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.6.1)\n","Requirement already satisfied: jiwer>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.0.0)\n","Requirement already satisfied: rapidfuzz>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (3.13.0)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (3.10.0)\n","Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (0.13.2)\n","Requirement already satisfied: plotly>=5.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (5.24.1)\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (4.67.1)\n","Requirement already satisfied: wandb>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.21.1)\n","Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (6.0.2)\n","Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.3.0)\n","Requirement already satisfied: jupyter>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (1.1.1)\n","Requirement already satisfied: ipywidgets>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (8.1.7)\n","Requirement already satisfied: jupyterlab>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (4.4.6)\n","Requirement already satisfied: lxml>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (5.4.0)\n","Requirement already satisfied: beautifulsoup4>=4.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (4.13.4)\n","Requirement already satisfied: editdistance>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (0.8.1)\n","Requirement already satisfied: Levenshtein>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (0.27.1)\n","Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (4.0.0)\n","Requirement already satisfied: accelerate>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (1.10.0)\n","Requirement already satisfied: deepspeed>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 52)) (0.17.4)\n","Requirement already satisfied: lightning>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 53)) (2.5.3)\n","Requirement already satisfied: black>=23.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 56)) (25.1.0)\n","Requirement already satisfied: flake8>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 57)) (7.3.0)\n","Requirement already satisfied: pytest>=7.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 58)) (8.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (0.34.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (25.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.35.0->-r requirements.txt (line 2)) (0.6.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35.0->-r requirements.txt (line 2)) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35.0->-r requirements.txt (line 2)) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35.0->-r requirements.txt (line 2)) (1.1.7)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 3)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (1.16.1)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (2.11.7)\n","Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (0.0.24)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations>=1.3.0->-r requirements.txt (line 10)) (4.12.0.88)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 10)) (3.12.6)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations>=1.3.0->-r requirements.txt (line 10)) (6.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 15)) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 15)) (3.6.0)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer>=3.0.0->-r requirements.txt (line 18)) (8.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 22)) (3.2.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.15.0->-r requirements.txt (line 24)) (9.1.2)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (3.1.45)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (5.29.5)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 28)) (2.34.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 10)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 10)) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations>=1.3.0->-r requirements.txt (line 10)) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.35.0->-r requirements.txt (line 2)) (2025.8.3)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.3.0->-r requirements.txt (line 32)) (4.9.3)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (6.5.7)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (6.1.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (7.16.6)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 35)) (6.17.1)\n","Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.2.3)\n","Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (7.34.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.14 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (4.0.14)\n","Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=8.0.0->-r requirements.txt (line 36)) (3.0.15)\n","Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.0.5)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.28.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (5.8.1)\n","Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.2.6)\n","Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.16.0)\n","Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.27.3)\n","Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.2.4)\n","Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (75.2.0)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0.0->-r requirements.txt (line 37)) (6.4.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.16.0)\n","Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (25.1.0)\n","Requirement already satisfied: jupyter-client>=7.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (7.4.9)\n","Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.12.0)\n","Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.5.3)\n","Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (5.10.4)\n","Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (7.7.0)\n","Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.22.1)\n","Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (26.2.1)\n","Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.18.1)\n","Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.8.0)\n","Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.17.0)\n","Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.12.1)\n","Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (4.25.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.12.0->-r requirements.txt (line 41)) (2.7)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 48)) (0.70.16)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (3.12.15)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.24.0->-r requirements.txt (line 49)) (5.9.5)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (0.8.1)\n","Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (3.1.0)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (1.1.1)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (1.13.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (9.0.0)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed>=0.10.0->-r requirements.txt (line 52)) (12.575.51)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 53)) (0.15.2)\n","Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 53)) (1.8.1)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.0.0->-r requirements.txt (line 53)) (2.5.3)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black>=23.0.0->-r requirements.txt (line 56)) (1.1.0)\n","Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black>=23.0.0->-r requirements.txt (line 56)) (0.12.1)\n","Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8>=6.0.0->-r requirements.txt (line 57)) (0.7.0)\n","Requirement already satisfied: pycodestyle<2.15.0,>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from flake8>=6.0.0->-r requirements.txt (line 57)) (2.14.0)\n","Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from flake8>=6.0.0->-r requirements.txt (line 57)) (3.4.0)\n","Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 58)) (2.1.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 58)) (1.6.0)\n","Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 58)) (2.19.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 48)) (1.20.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.3.1)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (25.1.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 28)) (4.0.12)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 28)) (5.0.2)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.8.15)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.1.7)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.6.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (3.0.51)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (4.9.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.2.13)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.8.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 3)) (3.0.2)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.27.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.4)\n","Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (3.3.0)\n","Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.1.4)\n","Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (0.1.1)\n","Requirement already satisfied: fqdn in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.5.1)\n","Requirement already satisfied: isoduration in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (20.11.0)\n","Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (3.0.0)\n","Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.1.0)\n","Requirement already satisfied: uri-template in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.3.0)\n","Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (24.11.1)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.10.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.5.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.21.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.0->-r requirements.txt (line 36)) (0.7.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 13)) (1.17.0)\n","Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.2.2)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.22)\n","Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (1.3.0)\n","Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.11/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0.0->-r requirements.txt (line 37)) (2.9.0.20250809)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 35)) (0.2.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 35)) (1.3.1)\n","‚úÖ Dependencies installed successfully!\n","üî• Key libraries checked:\n","  - Transformers: 4.55.1\n","  - PyTorch: 2.6.0+cu124\n","  - CUDA available: True\n","‚úÖ Custom modules imported successfully!\n"]}],"source":["# B∆∞·ªõc 3: C√†i ƒë·∫∑t dependencies\n","print(\"üì¶ Installing dependencies...\")\n","\n","# C·∫≠p nh·∫≠t pip v√† c√†i ƒë·∫∑t requirements\n","!pip install --upgrade pip\n","!pip install -r requirements.txt\n","\n","# C√†i ƒë·∫∑t th√™m m·ªôt s·ªë packages c√≥ th·ªÉ thi·∫øu\n","!pip install datasets>=2.14.0\n","!pip install accelerate>=0.24.0\n","!pip install jiwer>=3.0.0\n","\n","print(\"‚úÖ Dependencies installed successfully!\")\n","\n","# Ki·ªÉm tra installations quan tr·ªçng\n","try:\n","    import transformers\n","    import torch\n","    from PIL import Image\n","    import pandas as pd\n","    import numpy as np\n","    print(f\"üî• Key libraries checked:\")\n","    print(f\"  - Transformers: {transformers.__version__}\")\n","    print(f\"  - PyTorch: {torch.__version__}\")\n","    print(f\"  - CUDA available: {torch.cuda.is_available()}\")\n","except ImportError as e:\n","    print(f\"‚ùå Import error: {e}\")\n","\n","# Test import custom modules\n","try:\n","    from src.data_loader import CdSDataLoader\n","    from src.model import TrOCRForCdS\n","    from src.trainer import TrOCRTrainer\n","    print(\"‚úÖ Custom modules imported successfully!\")\n","except ImportError as e:\n","    print(f\"‚ùå Custom module import error: {e}\")\n","    print(\"üëâ Make sure you uploaded the src/ folder correctly\")\n"]},{"cell_type":"code","source":["# Fix paths trong config cho Colab\n","print(\"üîß Fixing data paths for Colab...\")\n","\n","# ƒê·ªçc v√† s·ª≠a config\n","import yaml\n","\n","# Load config hi·ªán t·∫°i\n","with open('config/colab_config.yaml', 'r') as f:\n","    config = yaml.safe_load(f)\n","\n","# C·∫≠p nh·∫≠t paths cho Colab\n","PROJECT_ROOT = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR\"\n","DATA_DIR = f\"{PROJECT_ROOT}/training-data\"\n","\n","# S·ª≠a source_dirs\n","config['data']['source_dirs'] = [\n","    f\"{DATA_DIR}/verite-terrain/\",\n","    f\"{DATA_DIR}/sample-images/\",\n","    f\"{DATA_DIR}/predic-corrigees/\"\n","]\n","\n","# S·ª≠a output paths\n","config['data']['output_dir'] = f\"{PROJECT_ROOT}/outputs/data/\"\n","config['paths']['models_dir'] = f\"{PROJECT_ROOT}/outputs/models/\"\n","config['paths']['outputs_dir'] = f\"{PROJECT_ROOT}/outputs/\"\n","config['paths']['logs_dir'] = f\"{PROJECT_ROOT}/outputs/logs/\"\n","\n","# L∆∞u l·∫°i config ƒë√£ fix\n","with open('config/colab_config_fixed.yaml', 'w') as f:\n","    yaml.dump(config, f, default_flow_style=False)\n","\n","print(\"‚úÖ Config paths fixed!\")\n","\n","# Ki·ªÉm tra paths c√≥ t·ªìn t·∫°i kh√¥ng\n","print(\"\\nüìÅ Checking data directories:\")\n","for source_dir in config['data']['source_dirs']:\n","    if os.path.exists(source_dir):\n","        files = os.listdir(source_dir)\n","        print(f\"  ‚úÖ {source_dir}: {len(files)} files\")\n","        # Show examples\n","        img_files = [f for f in files if f.lower().endswith(('.jpg', '.tif', '.png'))]\n","        xml_files = [f for f in files if f.lower().endswith('.xml')]\n","        print(f\"     Images: {len(img_files)}, XML: {len(xml_files)}\")\n","        if img_files:\n","            print(f\"     Example: {img_files[0]}\")\n","    else:\n","        print(f\"  ‚ùå {source_dir}: NOT FOUND\")\n","        print(f\"     üëâ Need to upload data to this path\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOXnOxXCFDIf","executionInfo":{"status":"ok","timestamp":1755403377325,"user_tz":-420,"elapsed":17,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"4210e22c-21f5-4f85-d0c2-1c9412fabfbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Fixing data paths for Colab...\n","‚úÖ Config paths fixed!\n","\n","üìÅ Checking data directories:\n","  ‚úÖ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/verite-terrain/: 78 files\n","     Images: 33, XML: 45\n","     Example: CdS02_Konv002-01_0034.jpg\n","  ‚úÖ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/sample-images/: 107 files\n","     Images: 107, XML: 0\n","     Example: CdS02_Konv002-02_0001.tif\n","  ‚úÖ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/predic-corrigees/: 20 files\n","     Images: 0, XML: 20\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"zRLFkEcjBW8i","executionInfo":{"status":"ok","timestamp":1755403380271,"user_tz":-420,"elapsed":2945,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"77994090-de3f-4735-d14d-29a8c83ee6d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Data exploration with fixed config...\n","‚úÖ Fixed configuration loaded\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","/content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr/src/data_loader.py:111: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  transforms.append(A.GaussNoise(var_limit=(0, aug_config['noise_factor']), p=0.2))\n"]},{"output_type":"stream","name":"stdout","text":["üîç Scanning for training data...\n","üìä Data Summary:\n","  - Total image-text pairs: 33\n","  - Average text length: 2360.2 characters\n","‚úÖ Data found successfully!\n","üìù Sample text: Chacun connait cet apologue : \"Un peintre avait expos√© un tableau repr√©sentant un lion terrass√© \"par...\n","üñºÔ∏è Sample image: /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/verite-terrain/CdS02_Konv002-01_0034.jpg\n","  - Min text length: 1180\n","  - Max text length: 3927\n","  - Texts under 10 chars: 0\n","\n","üìÅ Final data directories check:\n","  ‚úÖ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/verite-terrain/\n","     üì∑ Images: 33\n","     üìÑ XML files: 45\n","     üîó Matching pairs found: 33\n","  ‚úÖ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/sample-images/\n","     üì∑ Images: 107\n","     üìÑ XML files: 0\n","     üîó Matching pairs found: 0\n","  ‚úÖ /content/drive/MyDrive/Constance_de_Salm_TrOCR/training-data/predic-corrigees/\n","     üì∑ Images: 0\n","     üìÑ XML files: 20\n","     üîó Matching pairs found: 0\n"]}],"source":["print(\"üìä Data exploration with fixed config...\")\n","\n","from src.data_loader import CdSDataLoader\n","from src.utils import load_config\n","\n","# Load config ƒë√£ fix\n","config = load_config('config/colab_config_fixed.yaml', 'config/base_config.yaml')\n","print(\"‚úÖ Fixed configuration loaded\")\n","\n","# Initialize data loader\n","data_loader = CdSDataLoader(config)\n","\n","# Find data\n","print(\"üîç Scanning for training data...\")\n","image_paths, texts = data_loader.find_image_text_pairs(config['data']['source_dirs'])\n","\n","print(f\"üìä Data Summary:\")\n","print(f\"  - Total image-text pairs: {len(image_paths)}\")\n","\n","if len(texts) > 0:\n","    avg_length = sum(len(text) for text in texts) / len(texts)\n","    print(f\"  - Average text length: {avg_length:.1f} characters\")\n","    print(f\"‚úÖ Data found successfully!\")\n","    print(f\"üìù Sample text: {texts[0][:100]}...\")\n","    print(f\"üñºÔ∏è Sample image: {image_paths[0]}\")\n","\n","    # Show text length distribution\n","    lengths = [len(text) for text in texts]\n","    print(f\"  - Min text length: {min(lengths)}\")\n","    print(f\"  - Max text length: {max(lengths)}\")\n","    print(f\"  - Texts under 10 chars: {sum(1 for l in lengths if l < 10)}\")\n","\n","else:\n","    print(f\"‚ùå No training data found!\")\n","    print(f\"üëâ Ki·ªÉm tra l·∫°i data paths:\")\n","    for source_dir in config['data']['source_dirs']:\n","        print(f\"   {source_dir}\")\n","\n","print(f\"\\nüìÅ Final data directories check:\")\n","for source_dir in config['data']['source_dirs']:\n","    if os.path.exists(source_dir):\n","        files = os.listdir(source_dir)\n","        img_files = [f for f in files if f.lower().endswith(('.jpg', '.tif', '.png', '.jpeg'))]\n","        xml_files = [f for f in files if f.lower().endswith('.xml')]\n","        print(f\"  ‚úÖ {source_dir}\")\n","        print(f\"     üì∑ Images: {len(img_files)}\")\n","        print(f\"     üìÑ XML files: {len(xml_files)}\")\n","        print(f\"     üîó Matching pairs found: {len([img for img in img_files if any(xml.startswith(img.split('.')[0]) for xml in xml_files)])}\")\n","    else:\n","        print(f\"  ‚ùå {source_dir}: NOT FOUND\")"]},{"cell_type":"code","source":["print(\"üéØ Preparing for training with 33 samples...\")\n","\n","# Update config ƒë·ªÉ ph√π h·ª£p v·ªõi dataset nh·ªè\n","import yaml\n","\n","# Load config\n","with open('config/colab_config_fixed.yaml', 'r') as f:\n","    config = yaml.safe_load(f)\n","\n","# ƒêi·ªÅu ch·ªânh cho dataset nh·ªè (33 samples)\n","config['training'].update({\n","    'batch_size': 1,                    # Batch size nh·ªè\n","    'gradient_accumulation_steps': 4,   # Effective batch = 4\n","    'num_epochs': 20,                   # TƒÉng epochs cho dataset nh·ªè\n","    'learning_rate': 5e-5,              # Learning rate cao h∆°n\n","    'save_steps': 10,                   # Save th∆∞·ªùng xuy√™n\n","    'eval_steps': 20,                   # Eval th∆∞·ªùng xuy√™n\n","    'logging_steps': 5,                 # Log chi ti·∫øt\n","    'warmup_steps': 10,                 # √çt warmup steps\n","    'early_stopping_patience': 5       # Patience cao h∆°n\n","})\n","\n","# ƒêi·ªÅu ch·ªânh data split cho dataset nh·ªè\n","config['data'].update({\n","    'train_split': 0.8,    # 26 samples train\n","    'val_split': 0.1,      # 3 samples val\n","    'test_split': 0.1      # 4 samples test\n","})\n","\n","# L∆∞u config optimized\n","with open('config/colab_small_dataset.yaml', 'w') as f:\n","    yaml.dump(config, f, default_flow_style=False)\n","\n","print(\"‚úÖ Config optimized for small dataset (33 samples)\")\n","\n","# Estimate training time\n","num_samples = 33\n","train_samples = int(num_samples * 0.8)  # 26 samples\n","batch_size = config['training']['batch_size']\n","gradient_accumulation_steps = config['training']['gradient_accumulation_steps']\n","num_epochs = config['training']['num_epochs']\n","\n","effective_batch_size = batch_size * gradient_accumulation_steps\n","steps_per_epoch = max(1, train_samples // effective_batch_size)\n","total_steps = steps_per_epoch * num_epochs\n","estimated_time_minutes = total_steps * 30 / 60  # ~30 seconds per step for small dataset\n","\n","print(f\"‚è±Ô∏è Training estimates:\")\n","print(f\"  - Total samples: {num_samples}\")\n","print(f\"  - Train/Val/Test: {train_samples}/3/4\")\n","print(f\"  - Effective batch size: {effective_batch_size}\")\n","print(f\"  - Steps per epoch: {steps_per_epoch}\")\n","print(f\"  - Total epochs: {num_epochs}\")\n","print(f\"  - Total steps: {total_steps}\")\n","print(f\"  - Estimated time: {estimated_time_minutes:.0f} minutes\")\n","\n","print(f\"\\nüöÄ Ready to start training!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJo5AkDVFuzR","executionInfo":{"status":"ok","timestamp":1755403380349,"user_tz":-420,"elapsed":22,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"78e35f97-de59-4450-bb28-65391929b503"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üéØ Preparing for training with 33 samples...\n","‚úÖ Config optimized for small dataset (33 samples)\n","‚è±Ô∏è Training estimates:\n","  - Total samples: 33\n","  - Train/Val/Test: 26/3/4\n","  - Effective batch size: 4\n","  - Steps per epoch: 6\n","  - Total epochs: 20\n","  - Total steps: 120\n","  - Estimated time: 60 minutes\n","\n","üöÄ Ready to start training!\n"]}]},{"cell_type":"code","source":["# Fix import paths cho scripts\n","print(\"üîß Fixing import paths...\")\n","\n","import sys\n","import os\n","\n","# ƒê·∫£m b·∫£o current directory ƒë√∫ng\n","current_dir = os.getcwd()\n","print(f\"Current directory: {current_dir}\")\n","\n","# Add paths to Python path\n","trocr_dir = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\"\n","if trocr_dir not in sys.path:\n","    sys.path.insert(0, trocr_dir)\n","\n","# Change to trocr directory\n","os.chdir(trocr_dir)\n","print(f\"Changed to: {os.getcwd()}\")\n","\n","# Test imports\n","try:\n","    from src.trainer import TrOCRTrainer\n","    from src.data_loader import CdSDataLoader\n","    from src.model import TrOCRForCdS\n","    print(\"‚úÖ All imports successful!\")\n","except ImportError as e:\n","    print(f\"‚ùå Import error: {e}\")\n","    print(\"üìÅ Checking src directory:\")\n","    if os.path.exists('src'):\n","        print(\"  ‚úÖ src/ directory exists\")\n","        src_files = os.listdir('src')\n","        print(f\"  üìÑ Files in src/: {src_files}\")\n","    else:\n","        print(\"  ‚ùå src/ directory not found!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ma5zpqYUGmr5","executionInfo":{"status":"ok","timestamp":1755403380398,"user_tz":-420,"elapsed":48,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"71dad807-ba81-4eb6-d9d0-c56dbd1f3554"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Fixing import paths...\n","Current directory: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n","Changed to: /content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr\n","‚úÖ All imports successful!\n"]}]},{"cell_type":"code","source":["# Fix TrainingArguments compatibility\n","print(\"üîß Fixing TrainingArguments compatibility...\")\n","\n","import transformers\n","print(f\"Transformers version: {transformers.__version__}\")\n","\n","# Check which parameter name is correct\n","from transformers import TrainingArguments\n","import inspect\n","\n","# Get the signature of TrainingArguments.__init__\n","sig = inspect.signature(TrainingArguments.__init__)\n","params = list(sig.parameters.keys())\n","\n","print(\"Available TrainingArguments parameters:\")\n","eval_params = [p for p in params if 'eval' in p.lower()]\n","print(f\"Evaluation-related params: {eval_params}\")\n","\n","# Check if it's 'evaluation_strategy' or 'eval_strategy'\n","if 'evaluation_strategy' in params:\n","    print(\"‚úÖ Uses 'evaluation_strategy'\")\n","    eval_strategy_param = 'evaluation_strategy'\n","elif 'eval_strategy' in params:\n","    print(\"‚úÖ Uses 'eval_strategy'\")\n","    eval_strategy_param = 'eval_strategy'\n","else:\n","    print(\"‚ùå No evaluation strategy parameter found\")\n","    eval_strategy_param = None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9cPjFnSHI8y","executionInfo":{"status":"ok","timestamp":1755403380402,"user_tz":-420,"elapsed":3,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"7e6dce06-d2aa-40b6-c060-8a0c6f15a3af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Fixing TrainingArguments compatibility...\n","Transformers version: 4.55.1\n","Available TrainingArguments parameters:\n","Evaluation-related params: ['do_eval', 'eval_strategy', 'per_device_eval_batch_size', 'per_gpu_eval_batch_size', 'eval_accumulation_steps', 'eval_delay', 'jit_mode_eval', 'bf16_full_eval', 'fp16_full_eval', 'eval_steps', 'eval_do_concat_batches', 'batch_eval_metrics', 'eval_on_start', 'eval_use_gather_object']\n","‚úÖ Uses 'eval_strategy'\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"iQDypA1WBW8i","executionInfo":{"status":"ok","timestamp":1755405505828,"user_tz":-420,"elapsed":1165015,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"6464e542-08ab-422b-9026-93ffa9559ed3"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîß Fixing model configuration...\n","üìä Initializing with fixed model config...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Model config fixed:\n","  decoder_start_token_id: 0\n","  pad_token_id: 1\n","  vocab_size: 50265\n","  max_length: 384\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Constance_de_Salm_TrOCR/trocr-htr/src/data_loader.py:111: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  transforms.append(A.GaussNoise(var_limit=(0, aug_config['noise_factor']), p=0.2))\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Data: Train=25, Val=4, Test=4\n","‚úÖ Trainer created with fixed model config\n","üî• Starting training (take 3 - with fixed config)...\n"]},{"output_type":"stream","name":"stderr","text":["`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [140/140 18:33, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>7.837000</td>\n","      <td>7.388140</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>6.775600</td>\n","      <td>6.829752</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>6.481700</td>\n","      <td>6.672448</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>6.335700</td>\n","      <td>6.589857</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>6.236100</td>\n","      <td>6.561946</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>6.161400</td>\n","      <td>6.563494</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>6.051200</td>\n","      <td>6.558358</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>5.950500</td>\n","      <td>6.560427</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>5.976800</td>\n","      <td>6.558934</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>5.890100</td>\n","      <td>6.568191</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>5.860600</td>\n","      <td>6.560747</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>5.881800</td>\n","      <td>6.559472</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>5.765000</td>\n","      <td>6.560268</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>5.699200</td>\n","      <td>6.558624</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3917: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 384, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","There were missing keys in the checkpoint model loaded: ['decoder.output_projection.weight'].\n"]},{"output_type":"stream","name":"stdout","text":["üéâ Training completed!\n","üìä Training Results:\n","  Final loss: 6.3331\n","  Steps completed: 140\n","üíæ Model saved to: /content/drive/MyDrive/Constance_de_Salm_TrOCR/outputs/models/final\n","üß™ Testing model v·ªõi m·ªôt sample...\n","üìù Sample prediction:\n","  Reference: 1818 (de Mme la Princesse de Salm) Lettre A Mr Raboteau Dyck, ce 6 D√©cembre, 1818. Un mot seulement,...\n","  Prediction: 18 ( M. A. M. de..,... de,.,,. de de., de. de√©..'..√©.,',,, de,,'.,√©,.', de de, de',.√©,,√©. de' de.' d...\n","üéâ Training and testing completed successfully!\n"]}],"source":["# üîß Fix model configuration v·ªõi decoder_start_token_id\n","print(\"üîß Fixing model configuration...\")\n","\n","from src.data_loader import CdSDataLoader\n","from src.model import TrOCRForCdS\n","from transformers import TrainingArguments, Trainer, VisionEncoderDecoderModel, TrOCRProcessor\n","from src.utils import load_config\n","import torch\n","\n","# Load config\n","config = load_config('config/colab_small_dataset.yaml', 'config/base_config.yaml')\n","PROJECT_ROOT = \"/content/drive/MyDrive/Constance_de_Salm_TrOCR\"\n","config['paths']['models_dir'] = f\"{PROJECT_ROOT}/outputs/models/\"\n","\n","import os\n","os.makedirs(config['paths']['models_dir'], exist_ok=True)\n","\n","print(\"üìä Initializing with fixed model config...\")\n","\n","# 1. Load model and processor manually v·ªõi config fix\n","model_name = config['model']['name']\n","processor = TrOCRProcessor.from_pretrained(model_name)\n","model = VisionEncoderDecoderModel.from_pretrained(model_name)\n","\n","# FIX: Set decoder_start_token_id\n","model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n","model.config.pad_token_id = processor.tokenizer.pad_token_id\n","\n","# Additional config fixes for training\n","model.config.vocab_size = model.config.decoder.vocab_size\n","model.config.max_length = config['model']['max_length']\n","model.config.no_repeat_ngram_size = 3\n","model.config.early_stopping = True\n","model.config.length_penalty = 2.0\n","model.config.num_beams = 4\n","\n","print(f\"‚úÖ Model config fixed:\")\n","print(f\"  decoder_start_token_id: {model.config.decoder_start_token_id}\")\n","print(f\"  pad_token_id: {model.config.pad_token_id}\")\n","print(f\"  vocab_size: {model.config.vocab_size}\")\n","print(f\"  max_length: {model.config.max_length}\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# 2. Data\n","data_loader = CdSDataLoader(config)\n","train_dataset, val_dataset, test_dataset = data_loader.create_datasets()\n","print(f\"‚úÖ Data: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n","\n","# 3. Fixed collate function\n","def collate_fn_fixed(batch):\n","    \"\"\"Fixed collate function for training\"\"\"\n","    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n","    labels = torch.stack([item['labels'] for item in batch])\n","\n","    return {\n","        'pixel_values': pixel_values,\n","        'labels': labels\n","    }\n","\n","# 4. TrainingArguments v·ªõi wandb disabled\n","training_args = TrainingArguments(\n","    output_dir=config['paths']['models_dir'],\n","    num_train_epochs=config['training']['num_epochs'],\n","    per_device_train_batch_size=config['training']['batch_size'],\n","    per_device_eval_batch_size=config['training']['batch_size'],\n","    gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n","    learning_rate=config['training']['learning_rate'],\n","    weight_decay=config['training']['weight_decay'],\n","    warmup_steps=config['training']['warmup_steps'],\n","    eval_strategy=\"steps\",\n","    eval_steps=10,\n","    save_strategy=\"steps\",\n","    save_steps=10,\n","    save_total_limit=3,\n","    logging_steps=5,\n","    logging_first_step=True,\n","    fp16=config['hardware']['mixed_precision'] == 'fp16',\n","    dataloader_num_workers=config['hardware']['dataloader_num_workers'],\n","    dataloader_pin_memory=config['hardware']['pin_memory'],\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    remove_unused_columns=False,\n","    push_to_hub=False,\n","    report_to=[],  # Empty list to disable all reporting including wandb\n","    run_name=\"trocr_colab_training\"\n",")\n","\n","# Disable wandb completely\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# 5. Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    processing_class=processor,  # Use processing_class instead of tokenizer\n","    data_collator=collate_fn_fixed\n",")\n","\n","print(\"‚úÖ Trainer created with fixed model config\")\n","\n","# 6. Start training\n","try:\n","    print(\"üî• Starting training (take 3 - with fixed config)...\")\n","\n","    train_result = trainer.train()\n","    print(\"üéâ Training completed!\")\n","\n","    print(f\"üìä Training Results:\")\n","    print(f\"  Final loss: {train_result.training_loss:.4f}\")\n","    print(f\"  Steps completed: {train_result.global_step}\")\n","\n","    # Save model manually\n","    final_model_path = f\"{PROJECT_ROOT}/outputs/models/final\"\n","    os.makedirs(final_model_path, exist_ok=True)\n","\n","    model.save_pretrained(final_model_path)\n","    processor.save_pretrained(final_model_path)\n","\n","    print(f\"üíæ Model saved to: {final_model_path}\")\n","\n","    # Test m·ªôt sample prediction\n","    print(\"üß™ Testing model v·ªõi m·ªôt sample...\")\n","    model.eval()\n","    with torch.no_grad():\n","        test_sample = test_dataset[0]\n","        pixel_values = test_sample['pixel_values'].unsqueeze(0).to(device)\n","        generated_ids = model.generate(pixel_values, max_length=384)\n","        prediction = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","        reference = test_sample['text']\n","\n","        print(f\"üìù Sample prediction:\")\n","        print(f\"  Reference: {reference[:100]}...\")\n","        print(f\"  Prediction: {prediction[:100]}...\")\n","\n","    print(\"üéâ Training and testing completed successfully!\")\n","\n","except Exception as e:\n","    print(f\"‚ùå Training failed: {e}\")\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ruVH2vQkBW8i","executionInfo":{"status":"ok","timestamp":1755405680846,"user_tz":-420,"elapsed":59914,"user":{"displayName":"L√Ω L√™","userId":"14887723373539951567"}},"outputId":"981e379f-6796-4a0b-fb57-1a080b1c1926"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Comprehensive Model Evaluation\n","==================================================\n","‚úÖ Trained model loaded for evaluation\n","üîç Evaluating on 4 test samples...\n","Sample 1:\n","  Reference: 1818 (de Mme la Princesse de Salm) Lettre A Mr Raboteau Dyck, ce 6 D√©cembre, 181...\n","  Prediction: 18 ( M. A. M la.,.. de. la,, de,√©.'.√©,', le. √†. et. le, √†, et, d. v. d, v, je. j...\n","  Length - Ref: 3580, Pred: 383\n","\n","Sample 2:\n","  Reference: Lettres ces gens l√† ne seront jamais heureux, ils ne m√©ritent pas de l'√™tre, ils...\n","  Prediction: Lre Mart Madame Madame,,..','., de. de'' de,√©.√©'√© de de√©√©, et. et, v, √†, le, d, ...\n","  Length - Ref: 2619, Pred: 337\n","\n","Sample 3:\n","  Reference: Lettre de Martini Madame. Je viens de recevoir votre petite lettre mais trop tar...\n","  Prediction: Lre Mart Madame Mart..,.'. de',' de,, de.√©'√© de√©,√©. et, et. v. le.re.i. d. √†. l....\n","  Length - Ref: 1315, Pred: 436\n","\n","Sample 4:\n","  Reference: Lettre de Martini Madame Je vous ai vu passer au haut de ma rue avant hier √† 2 h...\n","  Prediction: Lre Martiniett Madame Madame..'.,' de. de'',, de,.√©'√©,√© de de√©√©. et, et. v.i. le...\n","  Length - Ref: 1697, Pred: 412\n","\n","üìà FINAL EVALUATION RESULTS:\n","========================================\n","  CER: 0.8578\n","  WER: 0.9498\n","  EXACT_MATCH: 0.0000\n","  AVG_EDIT_DISTANCE: 2018.0000\n","  SIMILARITY_RATIO: 0.2359\n","\n","üéØ PERFORMANCE ANALYSIS:\n","  Training samples: 25\n","  Training epochs: 20\n","  Training time: ~19 minutes\n","  Final training loss: 5.699\n","  Validation loss: 6.559\n","  üéâ CER < 90% - Model h·ªçc ƒë∆∞·ª£c pattern c∆° b·∫£n!\n","  ‚úÖ Similarity > 20% - Model c√≥ ti·ªÅm nƒÉng\n"]}],"source":["# üìä ƒê√ÅNH GI√Å CHI TI·∫æT MODEL TRAINING\n","print(\"üìä Comprehensive Model Evaluation\")\n","print(\"=\" * 50)\n","\n","from src.evaluator import HTREvaluator\n","import torch\n","from torch.utils.data import DataLoader\n","\n","# Load trained model\n","final_model_path = f\"{PROJECT_ROOT}/outputs/models/final\"\n","trained_model = VisionEncoderDecoderModel.from_pretrained(final_model_path)\n","trained_processor = TrOCRProcessor.from_pretrained(final_model_path)\n","trained_model.to(device)\n","trained_model.eval()\n","\n","print(\"‚úÖ Trained model loaded for evaluation\")\n","\n","# Evaluate on test set\n","predictions = []\n","references = []\n","\n","print(f\"üîç Evaluating on {len(test_dataset)} test samples...\")\n","\n","with torch.no_grad():\n","    for i, test_sample in enumerate(test_dataset):\n","        # Get prediction\n","        pixel_values = test_sample['pixel_values'].unsqueeze(0).to(device)\n","\n","        # Try different generation strategies\n","        generated_ids = trained_model.generate(\n","            pixel_values,\n","            max_length=200,  # Shorter length to avoid repetition\n","            num_beams=3,     # Fewer beams\n","            early_stopping=True,\n","            no_repeat_ngram_size=2,  # Prevent repetition\n","            do_sample=False\n","        )\n","\n","        prediction = trained_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","        reference = test_sample['text']\n","\n","        predictions.append(prediction)\n","        references.append(reference)\n","\n","        print(f\"Sample {i+1}:\")\n","        print(f\"  Reference: {reference[:80]}...\")\n","        print(f\"  Prediction: {prediction[:80]}...\")\n","        print(f\"  Length - Ref: {len(reference)}, Pred: {len(prediction)}\")\n","        print()\n","\n","# Calculate metrics\n","evaluator = HTREvaluator({'case_sensitive': True, 'normalize_whitespace': True})\n","test_metrics = evaluator.compute_metrics(predictions, references)\n","\n","print(\"üìà FINAL EVALUATION RESULTS:\")\n","print(\"=\" * 40)\n","for metric, value in test_metrics.items():\n","    if metric in ['cer', 'wer', 'exact_match', 'similarity_ratio', 'avg_edit_distance']:\n","        print(f\"  {metric.upper()}: {value:.4f}\")\n","\n","# Compare v·ªõi baseline (random)\n","print(f\"\\nüéØ PERFORMANCE ANALYSIS:\")\n","print(f\"  Training samples: 25\")\n","print(f\"  Training epochs: 20\")\n","print(f\"  Training time: ~19 minutes\")\n","print(f\"  Final training loss: 5.699\")\n","print(f\"  Validation loss: 6.559\")\n","\n","if test_metrics['cer'] < 0.9:\n","    print(f\"  üéâ CER < 90% - Model h·ªçc ƒë∆∞·ª£c pattern c∆° b·∫£n!\")\n","else:\n","    print(f\"  ‚ö†Ô∏è CER cao - C·∫ßn th√™m data ho·∫∑c tuning\")\n","\n","if test_metrics['similarity_ratio'] > 0.2:\n","    print(f\"  ‚úÖ Similarity > 20% - Model c√≥ ti·ªÅm nƒÉng\")\n","else:\n","    print(f\"  ‚ùå Similarity th·∫•p - C·∫ßn c·∫£i thi·ªán\")"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}